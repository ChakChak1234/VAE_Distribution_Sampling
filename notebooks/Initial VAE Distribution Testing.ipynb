{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial VAE Distribution Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow numpy matplotlib pydot graphviz\n",
    "#!pip install --upgrade h5py\n",
    "\n",
    "import tensorflow\n",
    "\n",
    "print(f\"TensorFlow Version: {tensorflow.version.VERSION}\")\n",
    "\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample epsilon = N(0,I)\n",
    "# z = z_mean + sqrt(var) * epsilon\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=128,\n",
    "                 model_name=\"vae_mnist\"):\n",
    "    \"\"\"Plots labels and MNIST digits as a function of the 2D latent vector\n",
    "\n",
    "    # Arguments\n",
    "        models (tuple): encoder and decoder models\n",
    "        data (tuple): test data and label\n",
    "        batch_size (int): prediction batch size\n",
    "        model_name (string): which model is using this function\n",
    "    \"\"\"\n",
    "\n",
    "    encoder, decoder = models\n",
    "    x_test, y_test = data\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "    filename = os.path.join(model_name, \"vae_mean.png\")\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = encoder.predict(x_test,\n",
    "                                   batch_size=batch_size)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "    filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "    # display a 30x30 2D manifold of digits\n",
    "    n = 30\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-4, 4, n)\n",
    "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = (n - 1) * digit_size + start_range + 1\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Samples from \"Arbitrary\" Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.random.multivariate_normal([0,0], [[0.25,0],[0,0.25]], 5000)\n",
    "X2 = np.random.multivariate_normal([3,3], [[0.25,0],[0,0.25]], 5000)\n",
    "\n",
    "X = np.vstack([X1, X2])\n",
    "np.random.shuffle(X)\n",
    "\n",
    "min_x = min(X[:,0])\n",
    "max_x = max(X[:,0])\n",
    "\n",
    "min_y = min(X[:,1])\n",
    "max_y = max(X[:,1])\n",
    "\n",
    "X[:,0] = (X[:,0]-min_x)/(max_x - min_x)\n",
    "X[:,1] = (X[:,1]-min_y)/(max_y - min_y)\n",
    "\n",
    "x_train = X[:9000]\n",
    "x_test  = X[9000:]\n",
    "\n",
    "input_shape = (2,)\n",
    "\n",
    "intermediate_dim = 128\n",
    "batch_size = 128\n",
    "latent_dim = 2\n",
    "original_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model = encoder + decoder\n",
    "# build encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Dense(intermediate_dim, activation='relu', name='x')(inputs)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "x (Dense)                       (None, 128)          384         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            258         x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            258         x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "z (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 900\n",
      "Trainable params: 900\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n",
    "\n",
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(intermediate_dim, activation='relu', name='out_x')(latent_inputs)\n",
    "outputs = Dense(original_dim, activation='sigmoid', name='output')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "out_x (Dense)                (None, 128)               384       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output decoder missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to decoder.\n",
      "Model: \"vae_mlp\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 [(None, 2), (None, 2 900         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 2)            642         encoder[1][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_clip_by_value_7/Min [(None, 2)]          0           decoder[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_clip_by_value_7 (Te [(None, 2)]          0           tf_op_layer_clip_by_value_7/Minim\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_29 (TensorFlowO [(None, 2)]          0           tf_op_layer_clip_by_value_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_35 (TensorFlowO [(None, 2)]          0           tf_op_layer_clip_by_value_7[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_36 (TensorFlowO [(None, 2)]          0           tf_op_layer_sub_29[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x (Dense)                       (None, 128)          384         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Log_14 (TensorFlowO [(None, 2)]          0           tf_op_layer_add_35[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_28 (TensorFlowO [(None, 2)]          0           encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Log_15 (TensorFlowO [(None, 2)]          0           tf_op_layer_add_36[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            258         x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            258         x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_28 (TensorFlowO [(None, 2)]          0           encoder_input[0][0]              \n",
      "                                                                 tf_op_layer_Log_14[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_29 (TensorFlowO [(None, 2)]          0           tf_op_layer_sub_28[0][0]         \n",
      "                                                                 tf_op_layer_Log_15[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_38 (TensorFlowO [(None, 2)]          0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square_7 (TensorFlo [(None, 2)]          0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_37 (TensorFlowO [(None, 2)]          0           tf_op_layer_mul_28[0][0]         \n",
      "                                                                 tf_op_layer_mul_29[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_30 (TensorFlowO [(None, 2)]          0           tf_op_layer_add_38[0][0]         \n",
      "                                                                 tf_op_layer_Square_7[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp_7 (TensorFlowOp [(None, 2)]          0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Neg_7 (TensorFlowOp [(None, 2)]          0           tf_op_layer_add_37[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub_31 (TensorFlowO [(None, 2)]          0           tf_op_layer_sub_30[0][0]         \n",
      "                                                                 tf_op_layer_Exp_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_14 (TensorFlow [(None,)]            0           tf_op_layer_Neg_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_7 (TensorFlowOp [(None,)]            0           tf_op_layer_sub_31[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_30 (TensorFlowO [(None,)]            0           tf_op_layer_Mean_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_mul_31 (TensorFlowO [(None,)]            0           tf_op_layer_Sum_7[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_39 (TensorFlowO [(None,)]            0           tf_op_layer_mul_30[0][0]         \n",
      "                                                                 tf_op_layer_mul_31[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_15 (TensorFlow [()]                 0           tf_op_layer_add_39[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_loss_7 (AddLoss)            ()                   0           tf_op_layer_Mean_15[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,542\n",
      "Trainable params: 1,542\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 1s 89us/sample - loss: 1.3864 - val_loss: 1.3846\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 25us/sample - loss: 1.3840 - val_loss: 1.3858\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 1.3842 - val_loss: 1.3847\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 1.3840 - val_loss: 1.3844\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 1.3841 - val_loss: 1.3848\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 1.3841 - val_loss: 1.3846\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3841 - val_loss: 1.3843\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 1.3842 - val_loss: 1.3849\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000/9000 [==============================] - 0s 24us/sample - loss: 1.3841 - val_loss: 1.3843\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 1.3840 - val_loss: 1.3847\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 22us/sample - loss: 1.3841 - val_loss: 1.3843\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3841 - val_loss: 1.3847\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 22us/sample - loss: 1.3838 - val_loss: 1.3841\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 1.3839 - val_loss: 1.3857\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3842 - val_loss: 1.3848\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3841 - val_loss: 1.3848\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3840 - val_loss: 1.3860\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3839 - val_loss: 1.3848\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 25us/sample - loss: 1.3840 - val_loss: 1.3848\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3840 - val_loss: 1.3856\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3841 - val_loss: 1.3854\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3840 - val_loss: 1.3844\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3840 - val_loss: 1.3849\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 1.3842 - val_loss: 1.3841\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 1.3839 - val_loss: 1.3844\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3840 - val_loss: 1.3847\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3842 - val_loss: 1.3845\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3842 - val_loss: 1.3847\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 1.3838 - val_loss: 1.3840\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3841 - val_loss: 1.3848\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3839 - val_loss: 1.3857\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 22us/sample - loss: 1.3842 - val_loss: 1.3847\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 26us/sample - loss: 1.3839 - val_loss: 1.3857\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 1.3842 - val_loss: 1.3847\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3842 - val_loss: 1.3845\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3837 - val_loss: 1.3861\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3840 - val_loss: 1.3841\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 24us/sample - loss: 1.3841 - val_loss: 1.3846\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 28us/sample - loss: 1.3839 - val_loss: 1.3845\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 23us/sample - loss: 1.3839 - val_loss: 1.3840\n",
      "Epoch 41/50\n",
      "2688/9000 [=======>......................] - ETA: 0s - loss: 1.3845"
     ]
    }
   ],
   "source": [
    "models = (encoder, decoder)\n",
    "\n",
    "MSE = False\n",
    "WEIGHTS = False\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "# VAE loss = mse_loss or xent_loss + kl_loss\n",
    "if MSE:\n",
    "    reconstruction_loss = mse(inputs, outputs)\n",
    "else:\n",
    "    reconstruction_loss = binary_crossentropy(inputs,\n",
    "                                              outputs)\n",
    "\n",
    "reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()\n",
    "plot_model(vae,\n",
    "           to_file='vae_mlp.png',\n",
    "           show_shapes=True)\n",
    "\n",
    "if WEIGHTS:\n",
    "    vae.load_model('vae_mlp_mnist.h5')\n",
    "else:\n",
    "    # train the autoencoder\n",
    "    vae.fit(\n",
    "        x_train,\n",
    "        epochs=50,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None)\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Test = np.random.multivariate_normal([0,0], [[1,0],[0,1]], 1000)\n",
    "\n",
    "results = decoder.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results[:,0], results[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encoder.predict(x_test)[0]\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.scatter(encoded[:,0], encoded[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_0 = plt.scatter(X[:,0], X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_de = decoder.predict(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(en_de[:,0], en_de[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "through = vae.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(through[:,0], through[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_test[:,0], x_test[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
